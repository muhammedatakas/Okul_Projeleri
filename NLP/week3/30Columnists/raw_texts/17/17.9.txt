What was Sir Fred Goodwin thinking when he committed Royal Bank of Scotland to the fateful £48bn takeover of ABN Amro? And the bankers who piled into sub-prime CDOs and 100%-plus mortgages? As the City's turkeys come thudding home to roost, one by one, like howitzer shells, an urgent question is how and why previously successful people made such awful decisions - and whether such catastrophes can be avoided in future.

Actually, Goodwin may not have thought about it very much at all. If, as seems likely, he was confident he was on familiar ground, he may have leapt straight to his preferred course with only a cursory consideration of alternatives. And if he did, he wouldn't be alone.

In textbooks and conventional wisdom, improving decision-making is a matter of better analysis: clearer objectives and more astute discrimination between a range of options. Yet as a timely new book (Think Again, by Sydney Finkelstein, Jo Whitehead and Andrew Campbell) makes clear, rational analysis of this kind plays a surprisingly small part in most decisions, and the emotions a surprisingly large one.

Paradoxically, the problem is not that people are bad at making decisions. It's that, for most purposes, we are so good at it that we don't even know how it's done. Research described in the book shows that the extraordinary human ability to act on the basis of incomplete information in complex conditions can be subverted by the very short-cuts that are at the heart of the processing miracle: pattern recognition and what the authors call "emotional tagging".

Pattern recognition is self-explanatory. Emotional tags attached to the patterns of experience recognised are equally crucial. Emotions actually lead the decision-making process, providing focus and impetus to action - "feed, fight, flee or any other of the f-words" - without which the process would just be data-processing. The trouble is that both the short-cuts can be tricked, and since they are unconscious we have no way of recognising that it has happened.

For instance, although the banks' fall from grace happened after the book was finished, the authors speculate that Goodwin may have been misled by both his heart and his head. His previous experience, notes Whitehead, told him he could create value by buying sprawling rivals and aggressively taking out costs. This approach had worked well in the past, winning him a knighthood to boot. 

Past success (which is a neglected hazard, the authors note) may well have reinforced his determination to push ahead, even as the economic storm clouds were gathering. But conditions differed in critical respects from those he was familiar with. In a credit crunch, the balance sheet - both RBS's own and that of the target - was more important than cost-cutting potential. With the same information, rival Barclays backed off. Not only did RBS go ahead - it amplified the risk by offering cash.

Powerful prejudgments (for example, a strong belief that growth comes from high leverage and sweating capital) and emotional attachments (self-interest, ambition) all pushed in the same direction, apparently making Goodwin blind to the risks inherent in the worsening climate. With variations, similar stories could be told about Dick Fuld at Lehman Brothers, who also misinterpreted his experiences and missed opportunities to change course, and many other actors in the financial drama.

Which raises a second question: why didn't they shift their views until too late? Reversing the usual emphasis, Think Again argues that, given the unconscious nature of decision-making, it's all but impossible for individuals to eliminate mistakes through self-correction. Better, in their view, to develop awareness of "red-flag conditions" that signal danger and establish external safeguards that can challenge distorted thinking. 

Interestingly, it is errors that seem to be the key teachers here. Having spectacularly miscalculated over the Bay of Pigs, President Kennedy recognised the danger of getting the decision wrong in the Cuban missile crisis and counteracted it with a variety of measures - including setting up a "decision group" to provide challenge and debate, chaired by his brother. Contrast this with Tony Blair's inability to spot giant red flags over Iraq that were visible to most of the UK population. The invasion was apparently never even voted on in cabinet.

Safeguards at individual and corporate level have their limits. Some of us would argue that the credit crunch is the product of the biggest mistake of all - a lethal compounding of misleading experience, ideological prejudgment and turbocharged self-interest - in the shape of the financial sector's unshakeable belief in market efficiency. What are the safeguards against such meta-mistakes? Keeping the red flags flying suddenly takes on an unexpected new significance.

